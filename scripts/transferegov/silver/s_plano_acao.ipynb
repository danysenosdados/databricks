{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "122bc288-2b09-4d68-96b5-8e2981328a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# SILVER: TRANSFORMAÇÃO DO bronze.transferegov.<endpoint>\n",
    "# Limpeza, normalização, tipagem e escrita no catálogo Silver\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Widget para endpoint\n",
    "dbutils.widgets.text(\"endpoint\", \"plano_acao\")\n",
    "endpoint = dbutils.widgets.get(\"endpoint\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Lê a tabela bronze\n",
    "# -------------------------------------------------------------\n",
    "bronze_table = f\"bronze.transferegov.{endpoint}\"\n",
    "df = spark.table(bronze_table)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Normaliza nomes das colunas\n",
    "# -------------------------------------------------------------\n",
    "def normalize_col_name(c):\n",
    "    return (\n",
    "        c.lower()\n",
    "         .replace(\" \", \"_\")\n",
    "         .replace(\"-\", \"_\")\n",
    "         .replace(\"/\", \"_\")\n",
    "         .replace(\":\", \"_\")\n",
    "         .replace(\".\", \"_\")\n",
    "         .strip()\n",
    "    )\n",
    "\n",
    "df = df.toDF(*[normalize_col_name(c) for c in df.columns])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Função para inferir tipo de cada coluna\n",
    "# -------------------------------------------------------------\n",
    "def infer_and_cast(df, sample_size=50):\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        col = F.col(c)\n",
    "\n",
    "        sample = df.select(col).na.drop().limit(sample_size).toPandas()[c].astype(str)\n",
    "\n",
    "        tipo = \"string\"\n",
    "        # Se todos são inteiros sem ponto/vírgula\n",
    "        if sample.str.match(r\"^[0-9]+$\").all():\n",
    "            tipo = \"bigint\"\n",
    "        # Se todos são números (inteiros ou decimais com ponto/vírgula)\n",
    "        elif sample.str.match(r\"^[0-9]+([.,][0-9]+)?$\").all():\n",
    "            tipo = \"double\"\n",
    "        # Se todos são datas\n",
    "        elif sample.str.match(r\"^\\d{4}-\\d{2}-\\d{2}$\").all():\n",
    "            tipo = \"date\"\n",
    "        # Se todos são timestamps\n",
    "        elif sample.str.match(r\"^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$\").all():\n",
    "            tipo = \"timestamp\"\n",
    "\n",
    "        # aplica cast único na coluna inteira\n",
    "        if tipo == \"bigint\":\n",
    "            new_cols.append(F.expr(f\"try_cast({c} as bigint)\").alias(c))\n",
    "        elif tipo == \"double\":\n",
    "            new_cols.append(F.regexp_replace(col, \",\", \".\").cast(\"double\").alias(c))\n",
    "        elif tipo == \"date\":\n",
    "            new_cols.append(F.to_date(col, \"yyyy-MM-dd\").alias(c))\n",
    "        elif tipo == \"timestamp\":\n",
    "            new_cols.append(F.to_timestamp(col, \"yyyy-MM-dd HH:mm:ss\").alias(c))\n",
    "        else:\n",
    "            new_cols.append(col.alias(c))\n",
    "\n",
    "    return df.select(new_cols)\n",
    "\n",
    "df_silver = infer_and_cast(df)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Escreve no catálogo silver\n",
    "# -------------------------------------------------------------\n",
    "(\n",
    "    df_silver.write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .format(\"delta\")\n",
    "        .saveAsTable(f\"silver.transferegov.{endpoint}\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4749354560405353,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "s_plano_acao",
   "widgets": {
    "endpoint": {
     "currentValue": "plano_acao",
     "nuid": "755fe3ce-b0f8-4a55-a8e4-52df90627fc6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "plano_acao",
      "label": null,
      "name": "endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "plano_acao",
      "label": null,
      "name": "endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
